{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Carlos Eduardo Abdelmalack Simodo\n",
    "\n",
    "Nome: Luiz Fernando da Silva Borges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aten√ß√£o:** Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import emoji\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Antes da etapa abaixo, os tweets foram classificados manualmente usando a interface de classifica√ß√£o desenvolvida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reunimos os arquivos com os tweets e suas etiquetas de classifica√ß√£o em um √∫nico arquivo Excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Etiquetas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eu s√≥ acho, que todo mundo devia sair do whats...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vim no habibs</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@viscardivitor @mateus_habibs @bruno_ferraz16 ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>as vezes eu s√≥ queria ver uma troca√ß√£o de porr...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@mateus_habibs isso q eh foco</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tinha &amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;calabresa&amp;lt;&amp;lt;&amp;lt...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>habibs com entrega gr√°tis, estourei</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets  Etiquetas\n",
       "0  eu s√≥ acho, que todo mundo devia sair do whats...          3\n",
       "1                                      vim no habibs          3\n",
       "2  @viscardivitor @mateus_habibs @bruno_ferraz16 ...          3\n",
       "3  as vezes eu s√≥ queria ver uma troca√ß√£o de porr...          3\n",
       "4                      @mateus_habibs isso q eh foco          3\n",
       "5  tinha &gt;&gt;&gt;&gt;&gt;calabresa&lt;&lt;&lt...          2\n",
       "6                habibs com entrega gr√°tis, estourei          3"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#junta os dois arquivos excel em um unico\n",
    "df_mensagens_etiquetadas_1 = pd.read_excel('metade_k.xlsx') \n",
    "df_mensagens_etiquetadas_2 = pd.read_excel('metade_y.xlsx') \n",
    "\n",
    "#a coluna foi nomeada manualmente de 'Tweets'\n",
    "valores1 = df_mensagens_etiquetadas_1[['Tweets','Etiquetas']]\n",
    "valores2 = df_mensagens_etiquetadas_2[['Tweets','Etiquetas']]\n",
    "\n",
    "df_tabela_etiquetada = pd.concat([valores1, valores2])\n",
    "df_tabela_etiquetada.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos se existe pelo menos 252 tweets de cada tipo (positivo, negativo e irrelevante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3    653\n",
      "1    356\n",
      "2    263\n",
      "Name: Etiquetas, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#verifica se o numero de cada tipo etiquetas ultrapassa ou alcanca o minimo necessario\n",
    "distribuicao = df_tabela_etiquetada['Etiquetas'].value_counts()\n",
    "print(distribuicao)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separa o conjunto de tweets positivos, negativos e irrelevantes em dois dataframes: treino e teste. O dataframe de treino possui 2/3 da quantidade total de tweets coletados. O dataframe de teste possui 1/3 da quantidade total de tweets coletados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separar em teste e treino, tendo a mesma razao de porcentagem de cada tipo de etiqueta\n",
    "def separa_teste_treino(df):\n",
    "    #define a divisao\n",
    "    divisao=1/3\n",
    "    \n",
    "    #separa os dataframes em dois novos dataframes\n",
    "    df_teste, df_treino= np.split(df, [int(divisao*len(df))])\n",
    "\n",
    "    #junta os dfs em uma lista\n",
    "    novos_dfs = [df_teste,df_treino]\n",
    "    return novos_dfs\n",
    "\n",
    "#chama a funcao\n",
    "novos_dfs=separa_teste_treino(df_tabela_etiquetada)\n",
    "df_teste = novos_dfs[0]\n",
    "df_treino = novos_dfs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Etiquetas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>habibs √© tao lixo que da nojo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>ia no drive do habibs, baixava o vidro do carr...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>vou pia no habibs</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>j√° estava indo dormir mh irm√£ chegou c vrs esf...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>em 10 minutos pedi pro lucas:\\n\\npizza, habibs...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>eu comeria habibs dnv t√¥ com vontade kkkkk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>queria umas esfiha do habibs ü§§ü§§</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>pedi uma coisa e veio outra, q √≥dio desse habi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>pedi  comida  no habibs  e n chego ate agr  ka...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>so consigo pensa na esfiha de queijo do habibs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>848 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Tweets  Etiquetas\n",
       "424                      habibs √© tao lixo que da nojo          2\n",
       "425  ia no drive do habibs, baixava o vidro do carr...          3\n",
       "426                                  vou pia no habibs          3\n",
       "427  j√° estava indo dormir mh irm√£ chegou c vrs esf...          1\n",
       "428  em 10 minutos pedi pro lucas:\\n\\npizza, habibs...          3\n",
       "..                                                 ...        ...\n",
       "631         eu comeria habibs dnv t√¥ com vontade kkkkk          1\n",
       "632                    queria umas esfiha do habibs ü§§ü§§          1\n",
       "633  pedi uma coisa e veio outra, q √≥dio desse habi...          2\n",
       "634  pedi  comida  no habibs  e n chego ate agr  ka...          2\n",
       "635     so consigo pensa na esfiha de queijo do habibs          1\n",
       "\n",
       "[848 rows x 2 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Etiquetas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eu s√≥ acho, que todo mundo devia sair do whats...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vim no habibs</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@viscardivitor @mateus_habibs @bruno_ferraz16 ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>as vezes eu s√≥ queria ver uma troca√ß√£o de porr...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@mateus_habibs isso q eh foco</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>quem t√° c esfiha do habibs no √¥nibus??????????...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>n√£o vou mentir, queria t√° agora comendo cogume...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>@galas_oficial ah...vc que quiz dizer habibs?</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>@mateus_habibs @flavia_azambuja a isa vai fica...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>saudades do meu s6 que eu conseguia desligar a...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>424 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Tweets  Etiquetas\n",
       "0    eu s√≥ acho, que todo mundo devia sair do whats...          3\n",
       "1                                        vim no habibs          3\n",
       "2    @viscardivitor @mateus_habibs @bruno_ferraz16 ...          3\n",
       "3    as vezes eu s√≥ queria ver uma troca√ß√£o de porr...          3\n",
       "4                        @mateus_habibs isso q eh foco          3\n",
       "..                                                 ...        ...\n",
       "419  quem t√° c esfiha do habibs no √¥nibus??????????...          3\n",
       "420  n√£o vou mentir, queria t√° agora comendo cogume...          1\n",
       "421      @galas_oficial ah...vc que quiz dizer habibs?          3\n",
       "422  @mateus_habibs @flavia_azambuja a isa vai fica...          3\n",
       "423  saudades do meu s6 que eu conseguia desligar a...          3\n",
       "\n",
       "[424 rows x 2 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conta o numero de cada tipo de tweets no dataframe de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, 2 e 3 no dataframe de treino: [354 284 210]\n",
      "1, 2 e 3 no dataframe de teste: [299  72  53]\n"
     ]
    }
   ],
   "source": [
    "#conta o numero de vezes que cada etiqueta se repete e coloca numa lista\n",
    "distribuicao = df_treino['Etiquetas'].value_counts()\n",
    "lista_dos_numeros_de_cada_tipo_de_etiqueta_treino = distribuicao.to_numpy()\n",
    "print(\"1, 2 e 3 no dataframe de treino:\", lista_dos_numeros_de_cada_tipo_de_etiqueta_treino)\n",
    "\n",
    "distribuicao = df_teste['Etiquetas'].value_counts()\n",
    "lista_dos_numeros_de_cada_tipo_de_etiqueta_teste = distribuicao.to_numpy()\n",
    "print(\"1, 2 e 3 no dataframe de teste:\", lista_dos_numeros_de_cada_tipo_de_etiqueta_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos filtrar os dois conjuntos de dados para\n",
    "    \n",
    "* Remover pontua√ß√µes\n",
    "* Remover links\n",
    "* Tornar todas as letras min√≠sculas \n",
    "* Colocar um espa√ßo antes e um depois de cada emoji\n",
    "* Substituir mais de um espa√ßamento entre dois elementos por apenas um"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove as pontua√ß√µes !-.:?;,%&*_+-\\/ e links\n",
    "def limpa_pontuacao_links(tweet_1):\n",
    "    \n",
    "    pontuacoes = '[!-.:?;,%&*_+-\\/|]'\n",
    "    padrao = re.compile(pontuacoes)\n",
    "    tweet_sem_pontuacoes = re.sub(padrao, \"\", tweet_1)\n",
    "    \n",
    "    tweet_sem_links = re.sub(\"http[^\\s]*\", \"\", tweet_sem_pontuacoes)\n",
    "    \n",
    "    tweet_sem_links = tweet_sem_links.replace(\"\\n\", \" \") ################# COMO TIRAR COM REGEX??!!\n",
    "    \n",
    "    return tweet_sem_links\n",
    "\n",
    "#minha_string = minha_string.replace('\\n', '')\n",
    "\n",
    "#faz com que cada emoji tenha um espa√ßo antes e depois dele\n",
    "def cerca_emoji(tweet_3):\n",
    "    lista_str_letras=\"\"\n",
    "    for letra in tweet_3:\n",
    "        if letra in emoji.UNICODE_EMOJI:\n",
    "            lista_str_letras = lista_str_letras + \" \" + letra + \" \"\n",
    "        else:\n",
    "            lista_str_letras = lista_str_letras + letra\n",
    "\n",
    "    return lista_str_letras\n",
    "\n",
    "#faz com que todas as letras sejam min√∫sculas e com apenas um espa√ßo entre duas palavras\n",
    "def minusculo_espacos(tweet_3):\n",
    "    \n",
    "    tweet_minusculo = tweet_3.lower()\n",
    "        \n",
    "    tweet_espacos = re.sub(\" +\",\" \", tweet_minusculo)\n",
    "    \n",
    "    return tweet_espacos\n",
    "\n",
    "#aplica as tr√™s fun√ß√µes acima de uma vez\n",
    "def filtro(tweet):\n",
    "    tweet = limpa_pontuacao_links(tweet)\n",
    "    tweet = cerca_emoji(tweet)\n",
    "    tweet = minusculo_espacos(tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplica os filtros citados para a coluna de tweets do dataframe de treino e salva em um novo dataframe filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Etiquetas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>habibs √© tao lixo que da nojo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>ia no drive do habibs baixava o vidro do carro...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>vou pia no habibs</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>j√° estava indo dormir mh irm√£ chegou c vrs esf...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>em 10 minutos pedi pro lucas pizza habibs mioj...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>a√≠ @ragazzo e @ifood eu pedi j√° t√° atrasado te...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>queria tanto comer umas esfirras do habibs ü•∫</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Tweets  Etiquetas\n",
       "424                      habibs √© tao lixo que da nojo          2\n",
       "425  ia no drive do habibs baixava o vidro do carro...          3\n",
       "426                                  vou pia no habibs          3\n",
       "427  j√° estava indo dormir mh irm√£ chegou c vrs esf...          1\n",
       "428  em 10 minutos pedi pro lucas pizza habibs mioj...          3\n",
       "429  a√≠ @ragazzo e @ifood eu pedi j√° t√° atrasado te...          2\n",
       "430      queria tanto comer umas esfirras do habibs ü•∫           1"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_treino_filtrado = df_treino\n",
    "df_treino_filtrado[\"Tweets\"]  = df_treino_filtrado[\"Tweets\"].apply(filtro)\n",
    "df_treino_filtrado.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplica os filtros citados para a coluna de tweets do dataframe de teste e salva em um novo dataframe filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Etiquetas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eu s√≥ acho que todo mundo devia sair do whatsa...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vim no habibs</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@viscardivitor @mateushabibs @brunoferraz16 am...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>as vezes eu s√≥ queria ver uma troca√ß√£o de porr...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@mateushabibs isso q eh foco</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tinha gtgtgtgtgtcalabresaltltltltltlt no meu p...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>habibs com entrega gr√°tis estourei</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets  Etiquetas\n",
       "0  eu s√≥ acho que todo mundo devia sair do whatsa...          3\n",
       "1                                      vim no habibs          3\n",
       "2  @viscardivitor @mateushabibs @brunoferraz16 am...          3\n",
       "3  as vezes eu s√≥ queria ver uma troca√ß√£o de porr...          3\n",
       "4                       @mateushabibs isso q eh foco          3\n",
       "5  tinha gtgtgtgtgtcalabresaltltltltltlt no meu p...          2\n",
       "6                 habibs com entrega gr√°tis estourei          3"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_teste_filtrado = df_teste\n",
    "df_teste_filtrado[\"Tweets\"]  = df_teste_filtrado[\"Tweets\"].apply(filtro)\n",
    "df_teste_filtrado.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando as series de tweets positivos, negativos e irrelevantes de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtro_positivo_treino = df_treino_filtrado[\"Etiquetas\"] == 1\n",
    "filtro_negativo_treino =  df_treino_filtrado[\"Etiquetas\"] == 2\n",
    "filtro_irrelevante_treino =  df_treino_filtrado[\"Etiquetas\"] == 3\n",
    "\n",
    "positivo_treino = df_treino_filtrado.loc[filtro_positivo_treino]\n",
    "negativo_treino = df_treino_filtrado.loc[filtro_negativo_treino]\n",
    "irrelevante_treino = df_treino_filtrado.loc[filtro_irrelevante_treino]\n",
    "\n",
    "serie_positivo_treino = positivo_treino[\"Tweets\"]\n",
    "serie_negativo_treino = negativo_treino[\"Tweets\"]\n",
    "serie_irrelevante_treino = irrelevante_treino[\"Tweets\"]\n",
    "serie_todos_tweets_treino = pd.concat([serie_positivo_treino, serie_negativo_treino, serie_irrelevante_treino])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fa√ßa aqui uma descri√ß√£o do seu produto e o que considerou como relevante ou n√£o relevante na classifica√ß√£o dos tweets.\n",
    "\n",
    "ESCREVA AQUI..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separando as s√©ries de tweets positivos, negativos e irrelantes do conjunto de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_positivo_treino = \" \".join(serie_positivo_treino)\n",
    "serie_positivo_treino = pd.Series(string_positivo_treino.split())\n",
    "\n",
    "string_negativo_treino = \" \".join(serie_negativo_treino)\n",
    "serie_negativo_treino = pd.Series(string_negativo_treino.split())\n",
    "\n",
    "string_irrelevante_treino = \" \".join(serie_irrelevante_treino)\n",
    "serie_irrelevante_treino = pd.Series(string_irrelevante_treino.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando as tabelas de frequ√™ncias relativas dos tweets positivos, negativos e irrelevantes do conjunto de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_relativa_positivo_treino = serie_positivo_treino.value_counts()\n",
    "tabela_relativa_negativo_treino = serie_negativo_treino.value_counts()\n",
    "tabela_relativa_irrelevante_treino = serie_irrelevante_treino.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando o conjunto que vai nos servir como o conjunto de todos os tweets existentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_todos_tweets_treino = string_positivo_treino + string_negativo_treino + string_irrelevante_treino\n",
    "serie_todos_tweets_treino = pd.Series(string_todos_tweets_treino.split())\n",
    "tabela_relativa_todos_tweets_treino = serie_todos_tweets_treino.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculando priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "probP = len(serie_positivo_treino)/len(serie_todos_tweets_treino)\n",
    "probN = len(serie_negativo_treino)/len(serie_todos_tweets_treino)\n",
    "probI = len(serie_irrelevante_treino)/len(serie_todos_tweets_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2843035343035343 0.2873354123354123 0.42853430353430355\n",
      "1.0001732501732503\n"
     ]
    }
   ],
   "source": [
    "print(probP, probN, probI)\n",
    "soma = probP+probN+probI\n",
    "print(soma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculando termos P(Tweet|Positivo), P(Tweet|Negativo), P(Tweet|Irrelevante) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alpha = 1.0\n",
    "#V = 435000\n",
    "alpha = 1\n",
    "V = 435000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_tweet_positivo(tweet_teste_1):\n",
    "    prob_tweet_positivo = 1            #evita underlow\n",
    "    for palavra in tweet_teste_1.split():\n",
    "        try:\n",
    "            prob_palavra_tweet_positivo = np.log((tabela_relativa_positivo_treino[palavra] + alpha) / \\\n",
    "            (len(string_positivo_treino) + alpha*V))\n",
    "            prob_tweet_positivo = prob_tweet_positivo + prob_palavra_tweet_positivo\n",
    "        except:\n",
    "            prob_palavra_tweet_positivo = np.log(alpha / (len(string_positivo_treino) + alpha*V))\n",
    "            prob_tweet_positivo = prob_tweet_positivo + prob_palavra_tweet_positivo\n",
    "             \n",
    "    return prob_tweet_positivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-47.17413388876251"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet = \"@michellebelo7 lula o primeiro\"\n",
    "\n",
    "prob_tweet_positivo(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_tweet_negativo(tweet_teste_2):\n",
    "    prob_tweet_negativo = 1             #evita underlow\n",
    "    for palavra in tweet_teste_2.split():\n",
    "        try:\n",
    "            prob_palavra_tweet_negativo = np.log((tabela_relativa_negativo_treino[palavra] + alpha) / \\\n",
    "            (len(string_negativo_treino) + alpha*V))\n",
    "            prob_tweet_negativo = prob_tweet_negativo + prob_palavra_tweet_negativo\n",
    "        except:\n",
    "            prob_palavra_tweet_negativo = np.log(alpha / (len(string_negativo_treino) + alpha*V))\n",
    "            prob_tweet_negativo = prob_tweet_negativo + prob_palavra_tweet_negativo\n",
    "        \n",
    "    return prob_tweet_negativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_tweet_irrelevante(tweet_teste_3):\n",
    "    prob_tweet_irrelevante = 1             #evita underlow\n",
    "    for palavra in tweet_teste_3.split():\n",
    "        try:\n",
    "            prob_palavra_tweet_irrelevante = np.log((tabela_relativa_irrelevante_treino[palavra] + alpha) /\\\n",
    "            (len(string_irrelevante_treino) + alpha*V))\n",
    "            prob_tweet_irrelevante = prob_tweet_irrelevante + prob_palavra_tweet_irrelevante \n",
    "        except:\n",
    "            prob_palavra_tweet_irrelevante = np.log(alpha / (len(string_irrelevante_treino) + alpha*V))\n",
    "            prob_tweet_irrelevante = prob_tweet_irrelevante + prob_palavra_tweet_irrelevante \n",
    "                \n",
    "    return prob_tweet_irrelevante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculando os termos P(Positivo|Tweet), P(Negativo|Tweet), P(Irrelavante|Tweet) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maior_prob(tweet_4):\n",
    "    prob_positivo_dado_tweet = np.log(probP) + prob_tweet_positivo(tweet_4)\n",
    "    prob_negativo_dado_tweet = np.log(probN) + prob_tweet_negativo(tweet_4)\n",
    "    prob_irrelevante_dado_tweet = np.log(probI) + prob_tweet_irrelevante(tweet_4)\n",
    "    \n",
    "    #print(prob_positivo_dado_tweet)\n",
    "    #print(prob_negativo_dado_tweet)\n",
    "    #print(prob_irrelevante_dado_tweet)\n",
    "    \n",
    "    if prob_positivo_dado_tweet > prob_negativo_dado_tweet and prob_positivo_dado_tweet > \\\n",
    "    prob_irrelevante_dado_tweet:\n",
    "        return 1\n",
    "    if prob_negativo_dado_tweet > prob_positivo_dado_tweet and  prob_negativo_dado_tweet > \\\n",
    "    prob_irrelevante_dado_tweet:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Etiquetas</th>\n",
       "      <th>Classificacao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eu s√≥ acho que todo mundo devia sair do whatsa...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vim no habibs</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@viscardivitor @mateushabibs @brunoferraz16 am...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>as vezes eu s√≥ queria ver uma troca√ß√£o de porr...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@mateushabibs isso q eh foco</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tinha gtgtgtgtgtcalabresaltltltltltlt no meu p...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>habibs com entrega gr√°tis estourei</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets  Etiquetas  Classificacao\n",
       "0  eu s√≥ acho que todo mundo devia sair do whatsa...          3              3\n",
       "1                                      vim no habibs          3              3\n",
       "2  @viscardivitor @mateushabibs @brunoferraz16 am...          3              3\n",
       "3  as vezes eu s√≥ queria ver uma troca√ß√£o de porr...          3              3\n",
       "4                       @mateushabibs isso q eh foco          3              3\n",
       "5  tinha gtgtgtgtgtcalabresaltltltltltlt no meu p...          2              3\n",
       "6                 habibs com entrega gr√°tis estourei          3              3"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_teste_classificador = df_teste\n",
    "df_teste_classificador[\"Classificacao\"] = df_teste_classificador[\"Tweets\"].apply(maior_prob)\n",
    "df_teste_classificador.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Classificacao</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Etiquetas</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.347826</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.236842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.521739</td>\n",
       "      <td>75.0</td>\n",
       "      <td>8.552632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39.130435</td>\n",
       "      <td>25.0</td>\n",
       "      <td>84.210526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Classificacao          1     2          3\n",
       "Etiquetas                                \n",
       "1              54.347826   0.0   7.236842\n",
       "2               6.521739  75.0   8.552632\n",
       "3              39.130435  25.0  84.210526"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(df_teste_classificador.Etiquetas,df_teste_classificador.Classificacao, normalize=\"columns\")*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 50/72= 69.44444444444444%\n",
      "2: 21/53= 39.62264150943396%\n",
      "3: 256/299= 85.61872909698997%\n"
     ]
    }
   ],
   "source": [
    "lista_classificacao = []\n",
    "lista_etiquetas = []\n",
    "acertos_1 = 0\n",
    "acertos_2 = 0\n",
    "acertos_3 = 0\n",
    "\n",
    "for n_linha in range(len(df_teste_classificador[\"Classificacao\"])):\n",
    "    lista_classificacao.append(df_teste_classificador[\"Classificacao\"].iloc[n_linha])\n",
    "    lista_etiquetas.append(df_teste_classificador[\"Etiquetas\"].iloc[n_linha])\n",
    "    \n",
    "    if df_teste_classificador[\"Classificacao\"].iloc[n_linha] == 1 and \\\n",
    "    df_teste_classificador[\"Etiquetas\"].iloc[n_linha] == 1:\n",
    "        acertos_1 += 1\n",
    "    elif df_teste_classificador[\"Classificacao\"].iloc[n_linha] == 2 and \\\n",
    "    df_teste_classificador[\"Etiquetas\"].iloc[n_linha] == 2:\n",
    "        acertos_2 += 1\n",
    "    elif df_teste_classificador[\"Classificacao\"].iloc[n_linha] == 3 and \\\n",
    "    df_teste_classificador[\"Etiquetas\"].iloc[n_linha] == 3:\n",
    "        acertos_3 += 1\n",
    "        \n",
    "etiquetas_1 = lista_etiquetas.count(1)\n",
    "etiquetas_2 = lista_etiquetas.count(2)\n",
    "etiquetas_3 = lista_etiquetas.count(3)\n",
    "\n",
    "acc_1 = (acertos_1/etiquetas_1) * 100\n",
    "acc_2 = (acertos_2/etiquetas_2) * 100\n",
    "acc_3 = (acertos_3/etiquetas_3) *100\n",
    "        \n",
    "print(\"1: {}/{}= {}%\".format(acertos_1, etiquetas_1, acc_1))\n",
    "print(\"2: {}/{}= {}%\".format(acertos_2, etiquetas_2, acc_2))\n",
    "print(\"3: {}/{}= {}%\".format(acertos_3, etiquetas_3, acc_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que realiza an√°lise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
