{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Carlos Simodo\n",
    "\n",
    "Nome: Luiz Fernando da Silva Borges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aten√ß√£o: Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Obten√ß√£o dos tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***[Preencha aqui o id da sua conta. Ex: @hoxie_reader ]***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dados de autentica√ß√£o do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @fulano\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. N√£o modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas para constru√ß√£o da base de dados:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'Lula'\n",
    "\n",
    "#Quantidade m√≠nima de mensagens capturadas:\n",
    "n = 3000\n",
    "\n",
    "#Quantidade m√≠nima de mensagens para a base de treinamento:\n",
    "t = 668\n",
    "\n",
    "#Filtro de l√≠ngua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documenta√ß√£o do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "    msgs.append(msg.full_text.lower())\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1002\n"
     ]
    }
   ],
   "source": [
    "#Embaralhando as mensagens para reduzir um poss√≠vel vi√©s temporal de obten√ß√£o \n",
    "\n",
    "shuffle(msgs)\n",
    "\n",
    "print(len(msgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1002"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs = list(set(list(msgs)))\n",
    "\n",
    "len(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma vez que a API capturou 2000 tweets, decidimos prosseguir com 1002 tweets no total. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1002"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_cortada = msgs[:1002]\n",
    "msgs = lista_cortada\n",
    "\n",
    "len(msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verifica se o arquivso n√£o existem para n√£o substituir um conjunto pronto\n",
    "if not os.path.isfile('./mensagens_1.xlsx') and os.path.isfile('./mensagens_2.xlsx'):\n",
    "    \n",
    "    #pega a quantidade de metade das mensagens escolhidas (deve ser par)\n",
    "    metade_mensagens = int(len(msgs)/2)\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer1 = pd.ExcelWriter(\"mensagens_1A.xlsx\")\n",
    "    writer2 = pd.ExcelWriter(\"mensagens_2A.xlsx\")\n",
    "    \n",
    "    #divide o conjunto de mensagens totais em duas planilhas, pois trata-se de um projeto em dupla\n",
    "    dft1 = pd.DataFrame({\"Tweets\": pd.Series(msgs[:metade_mensagens])})\n",
    "    dft2 = pd.DataFrame({\"Tweets\": pd.Series(msgs[metade_mensagens:])})\n",
    "    \n",
    "    #converte os data frames para arquivos .xlsx\n",
    "    dft1.to_excel(excel_writer = writer1, index = False)\n",
    "    writer1.save()\n",
    "    \n",
    "    dft2.to_excel(excel_writer = writer2, index = False)\n",
    "    writer2.save()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#junta os dois arquivos excel em um unico\n",
    "df_mensagens_etiquetadas_1 = pd.read_excel('tabela_etiquetada_1.xlsx') \n",
    "df_mensagens_etiquetadas_2 = pd.read_excel('tabela_etiquetada_2.xlsx') \n",
    "\n",
    "#a coluna foi nomeada manualmente de 'Tweets'\n",
    "valores1 = df_mensagens_etiquetadas_1[['Tweets','Etiquetas']]\n",
    "valores2 = df_mensagens_etiquetadas_2[['Tweets','Etiquetas']]\n",
    "\n",
    "df_tabela_etiquetada = pd.concat([valores1, valores2])\n",
    "#df_tabela_etiquetada\n",
    "#print(len(df_tabela_etiquetada['Etiquetas']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[579 267 156]\n",
      "156\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "#verifica se o numero de cada tipo etiquetas ultrapassa ou alcanca o minimo necessario\n",
    "\n",
    "    #valor minimo de cada tipo de etiqueta\n",
    "valor_minimo=252\n",
    "\n",
    "    #funcao responsavel pela verificacao\n",
    "def maior_que_250(df):\n",
    "    #define resposta padrao como verdadeiro\n",
    "    avancar=True\n",
    "    #conta o numero de vezes que cada etiqueta se repete e coloca numa lista\n",
    "    distribuicao = df['Etiquetas'].value_counts()\n",
    "    lista_dos_numeros_de_cada_tipo_de_etiqueta = distribuicao.to_numpy()\n",
    "    print(lista_dos_numeros_de_cada_tipo_de_etiqueta)\n",
    "    #caso algum dos numero nao passe, a resposta vai se tornar falsa\n",
    "    for valor in lista_dos_numeros_de_cada_tipo_de_etiqueta:\n",
    "        if valor>=valor_minimo:\n",
    "            pass\n",
    "        else:\n",
    "            print(valor)\n",
    "            avancar=False\n",
    "    return avancar\n",
    "\n",
    "print(maior_que_250(df_tabela_etiquetada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                                                Tweets  Etiquetas\n",
       " 399  @uol eu sou pt mas vai depender do candidato,t...          1\n",
       " 56   rt @leonicemariana1: pt confirma candidatura d...          1\n",
       " 401  os insens√≠veis desse desgoverno, n√£o ficam cho...          1\n",
       " 302  @evilzio5 @samiabomfim @geancarlobc @damaresal...          1\n",
       " 213  @agencialupa @redescordiais esse tes√£o que os ...          1\n",
       " ..                                                 ...        ...\n",
       " 413  rt @reportersalles: o l√≠der do governo na c√¢ma...          1\n",
       " 153  @veramagalhaes @gabilotta @fgv @felipesalto @i...          1\n",
       " 372  @oiiuiz verdade! n√£o se pode fazer com lula o ...          1\n",
       " 115  @inst_lula @lulaoficial #voltalula e salve o b...          1\n",
       " 287  rt @henr1quefragoso: a prop√≥sito da correta fa...          1\n",
       " \n",
       " [156 rows x 2 columns],\n",
       "                                                 Tweets  Etiquetas\n",
       " 31         rt @carlos38305595: faltou : lula √© ladr√£o.          2\n",
       " 124  rt @viniciuscfp82: arrasou! ministro do meio a...          2\n",
       " 106                    @uol cartilha do lula ladr√£o? ü§î          2\n",
       " 50   @brasil247 @tarsogenro o pt / lula est√£o mesmo...          2\n",
       " 191  rt @marleneffl: agora √© o luladr√£o \\n\\nhttps:/...          2\n",
       " ..                                                 ...        ...\n",
       " 126  @deputadofederal 89 mil dinheiro de esmola n√© ...          2\n",
       " 81   rt @ptbrasil: \"o lula √© um problema, o lula n√£...          2\n",
       " 481  pessoal, n√£o caiam no jogo do lula ao ver ele ...          2\n",
       " 113  @uol putz. ela j√° est√° avisando que vai roubar...          2\n",
       " 144  rt @o_antagonista: segundo palocci, lula sabia...          2\n",
       " \n",
       " [156 rows x 2 columns],\n",
       "                                                 Tweets  Etiquetas\n",
       " 20   rt @fabio____fso50: atual l√≠der do governo ric...          3\n",
       " 101  rt @o_antagonista: v√≠deo: lula defende bolsona...          3\n",
       " 258  @ighorb @agles_silva @rubensnunesmbl @vanessa_...          3\n",
       " 357  @terra por que nao conversa com o lula sobre i...          3\n",
       " 59   rt @yvimcarneiro: procede ? https://t.co/xopbh...          3\n",
       " ..                                                 ...        ...\n",
       " 0    rt @emirsader: lula: 'n√£o adianta eleger um pr...          3\n",
       " 166         @cwsperan eu n√£o t√¥ falando do lula???????          3\n",
       " 16   moreno moreno -  s√∫plica cearense (cover) http...          3\n",
       " 425  coitado do jair. foi demonizado porque quis em...          3\n",
       " 443  follow trick blackpink nsfw porn porn√¥ l√©sbica...          3\n",
       " \n",
       " [156 rows x 2 columns]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mesmo_numero(df):\n",
    "    #distribuicao de etiquetas\n",
    "    distribuicao = df['Etiquetas'].value_counts()\n",
    "\n",
    "    #obtem a contagem de cada etiqueta\n",
    "    lista_dos_numeros_de_cada_tipo_de_etiqueta = distribuicao.to_numpy()\n",
    "\n",
    "    #descobre o numero de aparicoes da etiqueta menos frequente\n",
    "    menor_numero=min(lista_dos_numeros_de_cada_tipo_de_etiqueta)\n",
    "\n",
    "    #cria filtros\n",
    "    filtro_p = df['Etiquetas'] == 1\n",
    "    filtro_n = df['Etiquetas'] == 2\n",
    "    filtro_i = df['Etiquetas'] == 3\n",
    "\n",
    "    #filtra o dataframe\n",
    "    df_p = df.loc[filtro_p]\n",
    "    df_n = df.loc[filtro_n]\n",
    "    df_i = df.loc[filtro_i]\n",
    "    \n",
    "    #reorganiza os dataframes\n",
    "    df_p = df_p.sample(frac = 1) \n",
    "    df_n = df_n.sample(frac = 1) \n",
    "    df_i = df_i.sample(frac = 1) \n",
    "    \n",
    "    #slicing\n",
    "    lista_p = df_p.iloc[0:menor_numero,]\n",
    "    lista_n = df_n.iloc[0:menor_numero,]\n",
    "    lista_i = df_i.iloc[0:menor_numero,]\n",
    "    \n",
    "    lista_data_frames=[lista_p,lista_n,lista_i]\n",
    "    return lista_data_frames\n",
    "\n",
    "lista_data_frames = mesmo_numero(df_tabela_etiquetada)\n",
    "lista_data_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Tweets  Etiquetas\n",
      "399  @uol eu sou pt mas vai depender do candidato,t...          1\n",
      "56   rt @leonicemariana1: pt confirma candidatura d...          1\n",
      "401  os insens√≠veis desse desgoverno, n√£o ficam cho...          1\n",
      "302  @evilzio5 @samiabomfim @geancarlobc @damaresal...          1\n",
      "213  @agencialupa @redescordiais esse tes√£o que os ...          1\n",
      "..                                                 ...        ...\n",
      "325              @luizpraieiro @rodrigomaia foi o lula          3\n",
      "433  rt @macunaimaz: @marialcab @trotzer2 @ocyarada...          3\n",
      "333  rt @jack_onil: @brumarquezine n tenho pol√≠tico...          3\n",
      "65   rt @fcomorais: @trotzer2 @ocyaradamasio @profe...          3\n",
      "221  @suzete040428071 suzy o que podemos fazer com ...          3\n",
      "\n",
      "[156 rows x 2 columns]\n",
      "                                                Tweets  Etiquetas\n",
      "20   rt @elisaraujo2010: lula falou sobre quest√£o d...          1\n",
      "361  lava jato inventa nova den√∫ncia contra lula ap...          1\n",
      "43   o que @lulaoficial disse sobre ricardo salles ...          1\n",
      "324  @taxanodividendo amei quando lula chamou ele d...          1\n",
      "109  rt @souguereira: pense numa vontade q eu t√¥ de...          1\n",
      "..                                                 ...        ...\n",
      "0    rt @emirsader: lula: 'n√£o adianta eleger um pr...          3\n",
      "166         @cwsperan eu n√£o t√¥ falando do lula???????          3\n",
      "16   moreno moreno -  s√∫plica cearense (cover) http...          3\n",
      "425  coitado do jair. foi demonizado porque quis em...          3\n",
      "443  follow trick blackpink nsfw porn porn√¥ l√©sbica...          3\n",
      "\n",
      "[312 rows x 2 columns]\n",
      "[52 52 52]\n",
      "[104 104 104]\n"
     ]
    }
   ],
   "source": [
    "#separar em teste e treino, tendo a mesma razao de porcentagem de cada tipo de etiqueta\n",
    "import numpy as np\n",
    "def separa_teste_treino(lista):\n",
    "    #define os termos da lista\n",
    "    df_p=lista[0]\n",
    "    df_n=lista[1]\n",
    "    df_i=lista[2]\n",
    "    \n",
    "    #define a divisao\n",
    "    divisao=1/3\n",
    "    \n",
    "    #separa os dataframes em dois novos dataframes\n",
    "    df_p_teste, df_p_treino= np.split(df_p, [int(divisao*len(df_p))])\n",
    "    df_n_teste, df_n_treino= np.split(df_n, [int(divisao*len(df_n))])\n",
    "    df_i_teste, df_i_treino= np.split(df_i, [int(divisao*len(df_i))])\n",
    "    \n",
    "    #junta os dfs parcias nos dfs de teste e treino\n",
    "    df_teste = pd.concat([df_p_teste, df_n_teste,df_i_teste],axis=0)\n",
    "    df_treino = pd.concat([df_p_treino, df_n_treino,df_i_treino],axis=0)\n",
    "    \n",
    "    #reorganiza os dfs\n",
    "    #df_teste = df_teste.sample(frac = 1)\n",
    "    #df_treino = df_treino.sample(frac = 1)\n",
    "\n",
    "    \n",
    "    #junta os dfs em uma lista\n",
    "    novos_dfs = [df_teste,df_treino]\n",
    "    return novos_dfs\n",
    "\n",
    "#chama a funcao\n",
    "novos_dfs=separa_teste_treino(lista_data_frames)\n",
    "df_teste = novos_dfs[0]\n",
    "df_treino = novos_dfs[1]\n",
    "print(df_teste)\n",
    "print(df_treino)\n",
    "\n",
    "#conta o numero de vezes que cada etiqueta se repete e coloca numa lista\n",
    "distribuicao = df_teste['Etiquetas'].value_counts()\n",
    "lista_dos_numeros_de_cada_tipo_de_etiqueta = distribuicao.to_numpy()\n",
    "print(lista_dos_numeros_de_cada_tipo_de_etiqueta)\n",
    "\n",
    "distribuicao = df_treino['Etiquetas'].value_counts()\n",
    "lista_dos_numeros_de_cada_tipo_de_etiqueta = distribuicao.to_numpy()\n",
    "print(lista_dos_numeros_de_cada_tipo_de_etiqueta)\n",
    "\n",
    "#testes\n",
    "#separa a funcao em df\n",
    "#df_p_teste = listas[0]\n",
    "#df_p_treino = listas[1]\n",
    "#df_n_teste = listas[2]\n",
    "#df_n_treino = listas[3]\n",
    "#df_i_teste = listas[4]\n",
    "#df_i_treino = listas[5]\n",
    "\n",
    "#print(len(df_p_teste.index))\n",
    "#print(len(df_p_treino.index))\n",
    "#print(len(df_n_teste.index))\n",
    "#print(len(df_n_treino.index))\n",
    "#print(len(df_i_teste.index))\n",
    "#print(len(df_i_treino.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "    \n",
    "    df_treinamento = df_tabela_etiquetada[:t]\n",
    "    df_treinamento.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = True) \n",
    "    \n",
    "    df_teste = df_tabela_etiquetada[t:]\n",
    "    df_teste.to_excel(excel_writer = writer, sheet_name = 'Teste', index = True) \n",
    "    \n",
    "    writer.save()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "Esta etapa √© manual. Fa√ßa a mesma pelo Excel.\n",
    "\n",
    "**Importante: Caso classifique um percentual pequeno de tweets relevantes ou de n√£o relevantes, deve voltar a este notebook e coletar mais tweets diferentes do produto escolhido pelo grupo.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
