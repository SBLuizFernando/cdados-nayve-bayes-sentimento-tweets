{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Carlos Simodo\n",
    "\n",
    "Nome: Luiz Fernando da Silva Borges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atenção: Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Obtenção dos tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***[Preencha aqui o id da sua conta. Ex: @hoxie_reader ]***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @fulano\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas para construção da base de dados:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'Lula'\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 3000\n",
    "\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 668\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "#api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "i = 1\n",
    "msgs_crus = []\n",
    "for msg_crus in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "    msgs_crus.append(msg_crus.full_text.lower())\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apaga retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apaga_rts(tweets_capturados):\n",
    "    lista = tweets_capturados\n",
    "    for e in lista:\n",
    "        if e.startswith('rt'):\n",
    "            indice = lista.index(e)\n",
    "            del lista[indice]\n",
    "        else:\n",
    "            pass\n",
    "    return lista\n",
    "\n",
    "msgs = apaga_rts(msgs_crus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1002\n"
     ]
    }
   ],
   "source": [
    "#Embaralhando as mensagens para reduzir um possível viés temporal de obtenção para a classificação\n",
    "\n",
    "shuffle(msgs)\n",
    "\n",
    "print(len(msgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1002"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs = list(set(list(msgs)))\n",
    "\n",
    "len(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma vez que a API capturou 2000 tweets, decidimos prosseguir com 1002 tweets no total. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1002"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_cortada = msgs[:1002]\n",
    "msgs = lista_cortada\n",
    "\n",
    "len(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos a quantidade de tweets igualmente para cada membro do grupo efetuar a classificação manual dos tweets em: positivo, negativo e irrelevante "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verifica se o arquivso não existem para não substituir um conjunto pronto\n",
    "if not os.path.isfile('./mensagens_1.xlsx') and os.path.isfile('./mensagens_2.xlsx'):\n",
    "    \n",
    "    #pega a quantidade de metade das mensagens escolhidas (deve ser par)\n",
    "    metade_mensagens = int(len(msgs)/2)\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer1 = pd.ExcelWriter(\"mensagens_1A.xlsx\")\n",
    "    writer2 = pd.ExcelWriter(\"mensagens_2A.xlsx\")\n",
    "    \n",
    "    #divide o conjunto de mensagens totais em duas planilhas, pois trata-se de um projeto em dupla\n",
    "    dft1 = pd.DataFrame({\"Tweets\": pd.Series(msgs[:metade_mensagens])})\n",
    "    dft2 = pd.DataFrame({\"Tweets\": pd.Series(msgs[metade_mensagens:])})\n",
    "    \n",
    "    #converte os data frames para arquivos .xlsx\n",
    "    dft1.to_excel(excel_writer = writer1, index = False)\n",
    "    writer1.save()\n",
    "    \n",
    "    dft2.to_excel(excel_writer = writer2, index = False)\n",
    "    writer2.save()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Antes da etapa abaixo, os tweets foram classificados manualmente usando a interface de classificação desenvolvida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reunimos os arquivos com os tweets e suas etiquetas de classificação em um único arquivo Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#junta os dois arquivos excel em um unico\n",
    "df_mensagens_etiquetadas_1 = pd.read_excel('tabela_etiquetada_1.xlsx') \n",
    "df_mensagens_etiquetadas_2 = pd.read_excel('tabela_etiquetada_2.xlsx') \n",
    "\n",
    "#a coluna foi nomeada manualmente de 'Tweets'\n",
    "valores1 = df_mensagens_etiquetadas_1[['Tweets','Etiquetas']]\n",
    "valores2 = df_mensagens_etiquetadas_2[['Tweets','Etiquetas']]\n",
    "\n",
    "df_tabela_etiquetada = pd.concat([valores1, valores2])\n",
    "#df_tabela_etiquetada\n",
    "#print(len(df_tabela_etiquetada['Etiquetas']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Etiquetas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1002.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.422156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.745568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Etiquetas\n",
       "count  1002.000000\n",
       "mean      2.422156\n",
       "std       0.745568\n",
       "min       1.000000\n",
       "25%       2.000000\n",
       "50%       3.000000\n",
       "75%       3.000000\n",
       "max       3.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tabela_etiquetada.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analise dos tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos se existe pelo menos 252 tweets de cada tipo (positivo, negativo e irrelevante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AxesSubplot(0.125,0.125;0.775x0.755)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#verifica se o numero de cada tipo etiquetas ultrapassa ou alcanca o minimo necessario\n",
    "distribuicao = df_tabela_etiquetada['Etiquetas'].value_counts().plot.bar()\n",
    "print(distribuicao)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separacao dos tweets nos dataframes de treino e de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separa_teste_e_treino_igualitario(df):\n",
    "    #define a divisao\n",
    "    divisao=1/3\n",
    "    \n",
    "    #separa os dataframes em dois novos dataframes\n",
    "    df_teste, df_treino= np.split(df, [int(divisao*len(df))])\n",
    "\n",
    "    return df_teste, df_treino\n",
    "\n",
    "df_teste = separa_teste_e_treino_igualitario(df_tabela_etiquetada)[0]\n",
    "df_treino = separa_teste_e_treino_igualitario(df_tabela_etiquetada)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conta o numero de cada tipo de tweets no dataframe de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[167 103  64]\n",
      "[412 164  92]\n",
      "1002\n"
     ]
    }
   ],
   "source": [
    "#conta o numero de vezes que cada etiqueta se repete e coloca numa lista\n",
    "distribuicao = df_teste['Etiquetas'].value_counts()\n",
    "lista_dos_numeros_de_cada_tipo_de_etiqueta_teste = distribuicao.to_numpy()\n",
    "print(lista_dos_numeros_de_cada_tipo_de_etiqueta_teste)\n",
    "\n",
    "distribuicao = df_treino['Etiquetas'].value_counts()\n",
    "lista_dos_numeros_de_cada_tipo_de_etiqueta_treino = distribuicao.to_numpy()\n",
    "print(lista_dos_numeros_de_cada_tipo_de_etiqueta_treino)\n",
    "\n",
    "print(sum(lista_dos_numeros_de_cada_tipo_de_etiqueta_teste + lista_dos_numeros_de_cada_tipo_de_etiqueta_treino))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vamos filtrar os dois conjuntos de dados para\n",
    "    \n",
    "* Remover pontuações\n",
    "* Remover links\n",
    "* Tornar todas as letras minísculas \n",
    "* Colocar um espaço antes e um depois de cada emoji\n",
    "* Substituir mais de um espaçamento entre dois elementos por apenas um"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "import re\n",
    "\n",
    "#Remove as pontuações !-.:?;,%&*_+-\\/ e links\n",
    "def limpa_pontuacao_links(tweet_1):\n",
    "    \n",
    "    pontuacoes = '[!-.:?;,%&*_+-\\/|]'\n",
    "    padrao = re.compile(pontuacoes)\n",
    "    tweet_sem_pontuacoes = re.sub(padrao, \"\", tweet_1)\n",
    "    \n",
    "    tweet_sem_links = re.sub(\"http[^\\s]*\", \"\", tweet_sem_pontuacoes)\n",
    "    \n",
    "    tweet_sem_links = tweet_sem_links.replace(\"\\n\", \" \") ################# COMO TIRAR COM REGEX??!!\n",
    "    \n",
    "    return tweet_sem_links\n",
    "\n",
    "#minha_string = minha_string.replace('\\n', '')\n",
    "\n",
    "#faz com que cada emoji tenha um espaço antes e depois dele\n",
    "def cerca_emoji(tweet_3):\n",
    "    lista_str_letras=\"\"\n",
    "    for letra in tweet_3:\n",
    "        if letra in emoji.UNICODE_EMOJI:\n",
    "            lista_str_letras = lista_str_letras + \" \" + letra + \" \"\n",
    "        else:\n",
    "            lista_str_letras = lista_str_letras + letra\n",
    "\n",
    "    return lista_str_letras\n",
    "\n",
    "#faz com que todas as letras sejam minúsculas e com apenas um espaço entre duas palavras\n",
    "def minusculo_espacos(tweet_3):\n",
    "    \n",
    "    tweet_minusculo = tweet_3.lower()\n",
    "        \n",
    "    tweet_espacos = re.sub(\" +\",\" \", tweet_minusculo)\n",
    "    \n",
    "    return tweet_espacos\n",
    "\n",
    "#aplica as três funções acima de uma vez\n",
    "def filtro(tweet):\n",
    "    tweet = limpa_pontuacao_links(tweet)\n",
    "    tweet = cerca_emoji(tweet)\n",
    "    tweet = minusculo_espacos(tweet)\n",
    "    return tweet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplica os filtros citados para a coluna de tweets do dataframe de treino e salva em um novo dataframe filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Etiquetas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>rt @uolnoticias pt confirma candidatura de ben...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>boa tarde patriotas deus é conservador o diabo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>@uol vamos seguir a cartilha do lula então sig...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>@nosdaimprensa @teteduche @xicosa leiase a est...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>@prsmalacheia @p0mb4g1ra burrismo mesmo foi qu...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>rt @ptnosenado perseguição repetida lava jato ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>@ferreiramaromba @raquela38128936 @lulaoficial...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Tweets  Etiquetas\n",
       "334  rt @uolnoticias pt confirma candidatura de ben...          3\n",
       "335  boa tarde patriotas deus é conservador o diabo...          2\n",
       "336  @uol vamos seguir a cartilha do lula então sig...          3\n",
       "337  @nosdaimprensa @teteduche @xicosa leiase a est...          3\n",
       "338  @prsmalacheia @p0mb4g1ra burrismo mesmo foi qu...          3\n",
       "339  rt @ptnosenado perseguição repetida lava jato ...          2\n",
       "340  @ferreiramaromba @raquela38128936 @lulaoficial...          1"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_treino_filtrado = df_treino\n",
    "df_treino_filtrado[\"Tweets\"]  = df_treino_filtrado[\"Tweets\"].apply(filtro)\n",
    "df_treino_filtrado.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplica os filtros citados para a coluna de tweets do dataframe de teste e salva em um novo dataframe filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Etiquetas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt @emirsader lula não adianta eleger um presi...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@macunaimaz @coelho7l @ath1abalba @eutrilheiro...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@veramagalhaes chama o lula</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amo que a luizianne vai se candidatar a prefei...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@belgranosouza @sidestranhe @rfmron @fernandoh...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@nane12958293 @lulemedeiros @lulaoficial vocês...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@ladyfontenelle são paulo já está quase sem na...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets  Etiquetas\n",
       "0  rt @emirsader lula não adianta eleger um presi...          3\n",
       "1  @macunaimaz @coelho7l @ath1abalba @eutrilheiro...          3\n",
       "2                        @veramagalhaes chama o lula          1\n",
       "3  amo que a luizianne vai se candidatar a prefei...          2\n",
       "4  @belgranosouza @sidestranhe @rfmron @fernandoh...          3\n",
       "5  @nane12958293 @lulemedeiros @lulaoficial vocês...          1\n",
       "6  @ladyfontenelle são paulo já está quase sem na...          2"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_teste_filtrado = df_teste\n",
    "df_teste_filtrado[\"Tweets\"]  = df_teste_filtrado[\"Tweets\"].apply(filtro)\n",
    "df_teste_filtrado.head(7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando as series de tweets positivos, negativos e irrelevantes de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtro_positivo_treino = df_treino_filtrado[\"Etiquetas\"] == 1\n",
    "filtro_negativo_treino =  df_treino_filtrado[\"Etiquetas\"] == 2\n",
    "filtro_irrelevante_treino =  df_treino_filtrado[\"Etiquetas\"] == 3\n",
    "\n",
    "positivo_treino = df_treino_filtrado.loc[filtro_positivo_treino]\n",
    "negativo_treino = df_treino_filtrado.loc[filtro_negativo_treino]\n",
    "irrelevante_treino = df_treino_filtrado.loc[filtro_irrelevante_treino]\n",
    "\n",
    "serie_positivo_treino = positivo_treino[\"Tweets\"]\n",
    "serie_negativo_treino = negativo_treino[\"Tweets\"]\n",
    "serie_irrelevante_treino = irrelevante_treino[\"Tweets\"]\n",
    "serie_todos_tweets_treino = pd.concat([serie_positivo_treino, serie_negativo_treino, serie_irrelevante_treino])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#debug\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando o classificador\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separando as séries de tweets positivos, negativos e irrelantes do conjunto de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_positivo_treino = \" \".join(serie_positivo_treino)\n",
    "serie_positivo_treino = pd.Series(string_positivo_treino.split())\n",
    "\n",
    "string_negativo_treino = \" \".join(serie_negativo_treino)\n",
    "serie_negativo_treino = pd.Series(string_negativo_treino.split())\n",
    "\n",
    "string_irrelevante_treino = \" \".join(serie_irrelevante_treino)\n",
    "serie_irrelevante_treino = pd.Series(string_irrelevante_treino.split())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando as tabelas de frequências relativas dos tweets positivos, negativos e irrelevantes do conjunto de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_relativa_positivo_treino = serie_positivo_treino.value_counts()\n",
    "tabela_relativa_negativo_treino = serie_negativo_treino.value_counts()\n",
    "tabela_relativa_irrelevante_treino = serie_irrelevante_treino.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando o conjunto que vai nos servir como o conjunto de todos os tweets existentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_todos_tweets_treino = string_positivo_treino + string_negativo_treino + string_irrelevante_treino\n",
    "\n",
    "serie_todos_tweets_treino = pd.Series(string_todos_tweets_treino.split())\n",
    "\n",
    "tabela_relativa_todos_tweets_treino = serie_todos_tweets_treino.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculando priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "probP = len(serie_positivo_treino)/len(serie_todos_tweets_treino)\n",
    "probN = len(serie_negativo_treino)/len(serie_todos_tweets_treino)\n",
    "probI = len(serie_irrelevante_treino)/len(serie_todos_tweets_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1323338525441329 0.25571131879543096 0.6120846313603323\n",
      "1.0001298026998962\n"
     ]
    }
   ],
   "source": [
    "print(probP, probN, probI)\n",
    "soma = probP+probN+probI\n",
    "print(soma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculando termos P(Tweet|Positivo), P(Tweet|Negativo), P(Tweet|Irrelevante) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_tweet_positivo(tweet_teste_1):\n",
    "    prob_tweet_positivo = 1            #evita underlow\n",
    "    for palavra in tweet_teste_1.split():\n",
    "        prob_palavra_tweet_positivo = tabela_relativa_positivo_treino[palavra]\n",
    "        prob_tweet_positivo = prob_tweet_positivo * prob_palavra_tweet_positivo\n",
    "        \n",
    "    return prob_tweet_positivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_tweet_negativo(tweet_teste_2):\n",
    "    prob_tweet_negativo = 1             #evita underlow\n",
    "    for palavra in tweet_teste_2.split():\n",
    "        prob_palavra_tweet_negativo = tabela_relativa_negativo_treino[palavra]\n",
    "        prob_tweet_negativo = prob_tweet_negativo * prob_palavra_tweet_negativo\n",
    "        \n",
    "    return prob_tweet_negativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_tweet_irrelevante(tweet_teste_3):\n",
    "    prob_tweet_irrelevante = 1             #evita underlow\n",
    "    for palavra in tweet_teste_3.split():\n",
    "        prob_palavra_tweet_irrelevante = tabela_relativa_irrelevante_treino[palavra]\n",
    "        prob_tweet_irrelevante = prob_tweet_irrelevante * prob_palavra_tweet_irrelevante\n",
    "        \n",
    "    return prob_tweet_irrelevante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculando os termos P(Positivo|Tweet), P(Negativo|Tweet), P(Irrelavante|Tweet) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "def maior_prob(tweet_4):\n",
    "    prob_positivo_dado_tweet = probP * prob_tweet_positivo(tweet_4)\n",
    "    prob_negativo_dado_tweet = probN * prob_tweet_negativo(tweet_4)\n",
    "    prob_irrelevante_dado_tweet = probI * prob_tweet_irrelevante(tweet_4)\n",
    "    \n",
    "    if prob_positivo_dado_tweet > prob_negativo_dado_tweet and prob_positivo_dado_tweet > \\\n",
    "    prob_irrelevante_dado_tweet:\n",
    "        return 1\n",
    "    if prob_negativo_dado_tweet > prob_positivo_dado_tweet and  prob_negativo_dado_tweet > \\\n",
    "    prob_irrelevante_dado_tweet:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "        \n",
    "\n",
    "tweet = \"@uol\"\n",
    "\n",
    "print(maior_prob(tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "Esta etapa é manual. Faça a mesma pelo Excel.\n",
    "\n",
    "**Importante: Caso classifique um percentual pequeno de tweets relevantes ou de não relevantes, deve voltar a este notebook e coletar mais tweets diferentes do produto escolhido pelo grupo.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
